@inproceedings{cohen2016group,
  title={Group equivariant convolutional networks},
  author={Cohen, Taco and Welling, Max},
  booktitle=ICML,
  pages={2990--2999},
  year={2016},
  organization={PMLR},
  annote={Considers only group of 90 deg rotations, superseded by Kondor2018}
}

@inproceedings{kondor2018generalization,
  title={On the generalization of equivariance and convolution in neural networks to the action of compact groups},
  author={Kondor, Risi and Trivedi, Shubhendu},
  booktitle=ICML,
  pages={2747--2755},
  year=2018,
  organization={PMLR},
  annote={group equivariance <=> group convolutions}
}

@article{herzig2018mapping,
  title={Mapping images to scene graphs with permutation-invariant structured prediction},
  author={Herzig, Roei and Raboh, Moshiko and Chechik, Gal and Berant, Jonathan and Globerson, Amir},
  journal=NIPS,
  volume={31},
  pages={7211--7221},
  year={2018},
  annote={Gives structure of permuation-invariant maps in the context of graph convolution. Consistent with comments from Korda2018, but proof less general.}
}

@inproceedings{ravanbakhsh2017equivariance,
  title={Equivariance through parameter-sharing},
  author={Ravanbakhsh, Siamak and Schneider, Jeff and Poczos, Barnabas},
  booktitle=ICML,
  pages={2892--2901},
  year=2017,
  organization={PMLR},
  annote={Shows that equivariances to discrete actions (permutations, discrete symmetries) are present if and only if some parameters are shared.}
}

@article{lyle2020benefits,
  author={Clare Lyle and Mark van der Wilk and Marta Kwiatkowska and Yarin Gal and Benjamin Bloem-Reddy},
  title={On the Benefits of Invariance in Neural Networks},
  year=2020,
  journal=CoRR,
  url={https://arxiv.org/abs/2005.00178},
  annote={proabilistically shows that feature averaging > data augmentation > nothing for generalization performance}
}

@inproceedings{cohen2019general,
  title={A General Theory of Equivariant CNNs on Homogeneous Spaces},
  author={Cohen, Taco S and Geiger, Mario and Weiler, Maurice},
  booktitle=NIPS,
  volume=32,
  year=2019,
  annote={Covers cases where input is an homogeneous space (e.g., sphere).}
}

@inproceedings{ravanbakhsh2020universal,
  title={Universal equivariant multilayer perceptrons},
  author={Ravanbakhsh, Siamak},
  booktitle=ICML,
  pages={7996--8006},
  year={2020},
  organization={PMLR},
  annote={Shows universality with a single layer.}
}

@misc{karras2021alias,
  title={Alias-Free Generative Adversarial Networks},
  author={Karras, Tero and Aittala, Miika and Laine, Samuli and H{\"a}rk{\"o}nen, Erik and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  note={arXiv preprint arXiv:2106.12423},
  year={2021},
  annote={Based on Nyquist theorem, discusses how to make output invariant to discretization.}
}


@article{bloem2020probabilistic,
  title={Probabilistic Symmetries and Invariant Neural Networks.},
  author={Bloem-Reddy, Benjamin and Teh, Yee Whye},
  journal=JMLR,
  volume={21},
  pages={90--1},
  year={2020},
  annote={Uses generalization of reparametrization trick to characterize symmetry (equivariance/invariance) in distribution to structure of functions.}
}

